<?xml version="1.0" encoding="UTF-8" ?>
<ChoregrapheProject xmlns="http://www.aldebaran-robotics.com/schema/choregraphe/project.xsd" xar_version="3">
    <Box name="root" id="-1" localization="8" tooltip="Root box of Choregraphe&apos;s behavior. Highest level possible." x="0" y="0">
        <bitmap>media/images/box/root.png</bitmap>
        <script language="4">
            <content>
                <![CDATA[]]>
</content>
        </script>
        <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
        <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
        <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" />
        <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="4" />
        <Timeline enable="0">
            <BehaviorLayer name="behavior_layer1">
                <BehaviorKeyframe name="keyframe1" index="1">
                    <Diagram>
                        <Box name="Say Text" id="1" localization="8" tooltip="Say the text received on its input." x="873" y="102">
                            <bitmap>media/images/box/interaction/say.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[import time

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)
        self.tts = ALProxy('ALTextToSpeech')
        self.ttsStop = ALProxy('ALTextToSpeech', True) #Create another proxy as wait is blocking if audioout is remote

    def onLoad(self):
        self.bIsRunning = False
        self.ids = []

    def onUnload(self):
        for id in self.ids:
            try:
                self.ttsStop.stop(id)
            except:
                pass
        while( self.bIsRunning ):
            time.sleep( 0.2 )

    def onInput_onStart(self, p):
        self.bIsRunning = True
        try:
            sentence = "you are"
            sentence += "\RSPD="+ str( self.getParameter("Speed (%)") ) + "\ "
            sentence += "\VCT="+ str( self.getParameter("Voice shaping (%)") ) + "\ "
            sentence += str(p)
            sentence +=  "\RST\ "
            id = self.tts.post.say(str(sentence))
            self.ids.append(id)
            self.tts.wait(id, 0)
        finally:
            try:
                self.ids.remove(id)
            except:
                pass
            if( self.ids == [] ):
                self.onStopped() # activate output of the box
                self.bIsRunning = False

    def onInput_onStop(self):
        self.onUnload()]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" />
                            <Input name="onStart" type="3" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this Input." id="2" />
                            <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this Input." id="3" />
                            <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when Box behavior is finished." id="4" />
                            <Parameter name="Voice shaping (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="150" tooltip='Used to modify at runtime the voice feature (tone, speed). In a slighty&#x0A;different way than pitch and speed, it gives a kind of &quot;gender or age&#x0A;modification&quot; effect.&#x0A;&#x0A;For instance, a quite good male derivation of female voice can be&#x0A;obtained setting this parameter to 78%.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the&#x0A;speed parameter. For example, if you want to decrease by 20% the voice&#x0A;shaping, you will have to increase by 20% the speed to keep a constant&#x0A;average speed.' id="5" />
                            <Parameter name="Speed (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="200" tooltip="Changes the speed of the voice.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the voice&#x0A;shaping parameter. For example, if you want to increase by 20% the speed, you&#x0A;will have to decrease by 20% the voice shaping to keep a constant average&#x0A;speed." id="6" />
                            <Resource name="Speech" type="Lock" timeout="0" />
                        </Box>
                        <Box name="Get Expression (1)" id="2" localization="8" tooltip="This box returns the detected facial expression of the person in front of the robot.&#x0A;The detection fails when there are more or less than one person in front of the robot or when the timeout is exceeded.&#x0A;&#x0A;It is possible to set up the Confidence Threshold and the Timeout parameters for this box. &#x0A;Furthermore it is possible to select the required emotions:&#x0A;- neutral&#x0A;- happy&#x0A;- surprised&#x0A;- angry&#x0A;- sad" x="649" y="170">
                            <bitmap>media/images/box/interaction/emotion.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[class MyClass(GeneratedClass):
    #this method is used to initialise the current objet
    def __init__(self):
        GeneratedClass.__init__(self)

    #this method is use to define and initialise current objet parameters.It will be call during the loading of the process
    def onLoad(self):
        try:
        #Get the ALFaceCharacteristics module in order to analye faces and get emotions
            self.faceC = ALProxy("ALFaceCharacteristics")
        #you have to be connect to a reel robot ifnot, an exception will occur
        except Exception as e:
            raise RuntimeError(str(e) + "Make sure you're not connected to a virtual robot." )
        #in the variable name confidence, we store the confidence Thereshold choose by the user to be                given to the robot.
        self.confidence = self.getParameter("Confidence Threshold")
        #we use the preceding confidence variable to define confidence threshold for each emotion to be detected.
        #Note that, because some emotions are more difficults to detect that order, the confidence threshold couldn't have the same value.Emotions more difficult to detect will have smaller confidence
        self.threshNeutralEmotion = self.confidence + 0.15
        self.threshHappyEmotion = self.confidence
        self.threshSurprisedEmotion = self.confidence + 0.05
        self.threshAngryEmotion = self.confidence + 0.2
        self.threshSadEmotion = self.confidence + 0.15
        #self.threshScaredEmotion = self.confidence + 0.15
        #emotions table
        self.emotions = ["neutral", "happy", "surprised", "angry", "sad","scared"]
        #this variable counter is use to capture and analyse several times faces in order to avoid mistakes
        self.counter = 0
        #this variable is used for states: running and not
        self.bIsRunning = False
        self.delayed = []
        self.errorMes = ""

        #get frame to display images.If an error occur, we display it in the console
        self.frameManager = None
        try:
            self.frameManager = ALProxy("ALFrameManager")
        except Exception as e:
            self.logger.error(e)
        self.ttx = ALProxy("ALTextToSpeech")

    #this method is call at the end of the process.It is use to reset variables and cancel delays
    def onUnload(self):
        self.counter = 0
        self.tProperties = [0,0,0,0,0]
        self.bIsRunning = False
        self.cancelDelays()

    #this method is used to get the service ALTabletService which allow the use of the robot tablet.   If an error occur, we display it on the console.the tablet service is return.
    def _getTabletService(self):
        tabletService = None
        try:
            tabletService = self.session().service("ALTabletService")
        except Exception as e:
            self.logger.error(e)
        return tabletService

    #this method is use to get absolute url of the image to be display on the robot screen.It take in parameter the current objet and the relative url.
    def _getAbsoluteUrl(self, partial_url):
        import os
        subPath = os.path.join(self.packageUid(), os.path.normpath(partial_url).lstrip("\\/"))
        # We create TabletService here in order to avoid
        # problems with connections and disconnections of the tablet during the life of the application
        return "http://%s/apps/%s" %(self._getTabletService().robotIp(), subPath.replace(os.path.sep, "/"))

    #this method is call when the start button is press in order to run the behavior
    def onInput_onStart(self):

        tabletService = ALProxy('ALTabletService')

        # load Application
        uid = self.packageUid()
        tabletService.loadApplication(uid)
        id = tabletService.showWebview()
        time.sleep(10)

        memory = ALProxy("ALMemory")
        self.code = 0

        for x in range(0, 20):
            try :
                self.code = memory.getData("GameStart")
                self.logger.info("game start code " + str(self.code))
                if(self.code == 1):
                    url = "images/"
                    try:
                        #start timer
                        import qi
                        import functools
                        delay_future = qi.async(self.onTimeout, delay=int(self.getParameter("Timeout (s)") * 1000 * 1000))
                        self.delayed.append(delay_future)
                        bound_clean = functools.partial(self.cleanDelay, delay_future)
                        delay_future.addCallback(bound_clean)
                        #table with the value of each emotion detected by the robot.Initialy,they are all null
                        self.tProperties = [0,0,0,0,0]
                        self.bIsRunning = True
                        while self.bIsRunning:
                            #we will captured and analyse four times each face in order to determine an emotion
                            if self.counter < 4:
                                try:
                                    #identify user
                                    ids = ALMemory.getData("PeoplePerception/PeopleList")
                                    if len(ids) == 0:
                                        self.errorMes = "No face detected"
                                        self.onUnload()
                                    elif len(ids) > 1:
                                        self.errorMes = "Multiple faces detected"
                                        self.onUnload()
                                    else:
                                        #analyze age properties
                                        self.faceC.analyzeFaceCharacteristics(ids[0])
                                        properties = ALMemory.getData("PeoplePerception/Person/"+str(ids[0])+"/ExpressionProperties")
                                        self.tProperties[0] += properties[0]
                                        self.tProperties[1] += properties[1]
                                        self.tProperties[2] += properties[2]
                                        self.tProperties[3] += properties[3]
                                        self.tProperties[4] += properties[4]
                                       # self.tProperties[5] += properties[5]
                                        self.counter += 1
                                except:
                                    ids = []
                            else:
                                self.counter = 0
                                recognized = [0,0,0,0,0]
                                #calculate mean value for neutral, happy, surprised,scared, angry or sad
                                self.tProperties[0] /= 4
                                self.tProperties[1] /= 4
                                self.tProperties[2] /= 4
                                self.tProperties[3] /= 4
                                self.tProperties[4] /= 4
                                #self.tProperties[5] /= 5

                                if self.getParameter("neutral") and self.tProperties[0] > self.threshNeutralEmotion:
                                    recognized[0] = self.tProperties[0]
                                if self.getParameter("happy") and self.tProperties[1] >self.threshHappyEmotion:
                                    recognized[1] = self.tProperties[1]
                                if self.getParameter("surprised") and self.tProperties[2] > self.threshSurprisedEmotion:
                                    recognized[2] = self.tProperties[2]
                                if self.getParameter("angry") and self.tProperties[3] > self.threshAngryEmotion:
                                    recognized[3] = self.tProperties[3]
                                if self.getParameter("sad") and self.tProperties[4] > self.threshSadEmotion:
                                    recognized[4] = self.tProperties[4]
                               # if self.getParameter("scared") and self.tProperties[5] > self.threshScaredEmotion:
                                   # recognized[5] = self.tProperties[5]

                                self.tProperties = [0,0,0,0,0]
                                try:
                                    if recognized != [0,0,0,0,0]:
                                        self.logger.info("trouve au tour" + str(x))
                                        emotion = self.emotions[recognized.index(max(recognized))]
                                        if(emotion == "surprised"):
                                            url += "surprise"
                                        #elif(emotion == "scared"):
                                            #url = "scare"
                                        else:
                                            url += emotion

                                        if tabletService:
                                            try:
                                                url += ".png"
                                                self.logger.info(url)
                                                if url == '':
                                                    self.logger.error("URL of the image is empty")
                                                if not url.startswith('http'):
                                                    url = self._getAbsoluteUrl(url)
                                                    url += emotion

                                                else:

                                                    tabletService.showImage(url)
                                                    future.value()
                                            except Exception as err:
                                                self.logger.error("Error during ShowImage : %s " % err)


                                        else:
                                            self.logger.warning("No ALTabletService, can't display the image.")
                                            self.onStopped()


                                    else:
                                        emotion = None
                                except:
                                    emotion = None
                                try:
                                    ALMemory.removeData("PeoplePerception/Person/"+str(ids[0])+"/ExpressionProperties")

                                except:
                                    pass
                                if emotion != None:
                                    self.onStopped(emotion)

                                    self.onUnload()

                        raise RuntimeError(self.errorMes)
                    except Exception as e:
                        raise RuntimeError(str(e))
                        self.onUnload()
                else :
                    self.say("no face detected")
            except Exception as err:
                self.logger.info("tour" + str(x))
                self.logger.error("Error: %s " % err)
            self.say("make another expression")
            time.sleep(2)

    def onTimeout(self):
        self.errorMes = "Timeout"
        self.onUnload()

    def cleanDelay(self, fut, fut_ref):
        self.delayed.remove(fut)

    def cancelDelays(self):
        cancel_list = list(self.delayed)
        for d in cancel_list:
            d.cancel()

    def onInput_onStop(self):
        self.onUnload()]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                            <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
                            <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" />
                            <Output name="onStopped" type="3" type_size="1" nature="1" inner="0" tooltip='Returns the facial expression of the person in front of the robot. &#x0A;- &quot;neutral&quot;&#x0A;- &quot;happy&quot;&#x0A;- &quot;surprised&quot;&#x0A;- &quot;angry&quot;&#x0A;- &quot;sad&quot;&#x0A;&#x0A;Tip:&#x0A;Connect this output to a &quot;Switch Case&quot; box containing the possible output values as strings. In this way you can trigger different paths in your behavior depending on the output.' id="4" />
                            <Output name="onError" type="3" type_size="1" nature="1" inner="0" tooltip='Triggered when gender detection failed. &#x0A;Possible error messages:&#x0A;- &quot;No face detected&quot;&#x0A;- &quot;Multiple faces detected&quot;&#x0A;- &quot;Timeout&quot;' id="5" />
                            <Parameter name="Confidence Threshold" inherits_from_parent="0" content_type="2" value="0.35" default_value="0.6" min="0" max="1" tooltip="Set the confidence threshold for the age detection." id="6" />
                            <Parameter name="Timeout (s)" inherits_from_parent="0" content_type="2" value="10" default_value="5" min="1" max="60" tooltip="" id="7" />
                            <Parameter name="neutral" inherits_from_parent="0" content_type="0" value="1" default_value="1" tooltip="" id="8" />
                            <Parameter name="happy" inherits_from_parent="0" content_type="0" value="1" default_value="1" tooltip="" id="9" />
                            <Parameter name="surprised" inherits_from_parent="0" content_type="0" value="1" default_value="1" tooltip="" id="10" />
                            <Parameter name="angry" inherits_from_parent="0" content_type="0" value="1" default_value="1" tooltip="" id="11" />
                            <Parameter name="sad" inherits_from_parent="0" content_type="0" value="1" default_value="1" tooltip="" id="12" />
                        </Box>
                        <Link inputowner="1" indexofinput="2" outputowner="2" indexofoutput="4" />
                        <Link inputowner="2" indexofinput="2" outputowner="0" indexofoutput="2" />
                    </Diagram>
                </BehaviorKeyframe>
            </BehaviorLayer>
        </Timeline>
    </Box>
</ChoregrapheProject>
